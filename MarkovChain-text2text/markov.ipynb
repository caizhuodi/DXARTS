{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b2daed-f3eb-44ce-8dff-734c6ce651ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<font color=\"#6A0DAD\">\n",
    "    \n",
    "## 1 separate: understand markov chain\n",
    "\n",
    "It's about probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551a530e-2a6c-451e-970b-e81c39f9fa1b",
   "metadata": {},
   "source": [
    "<font color=\"#6A0DAD\">\n",
    "    \n",
    "### 1.1 n-gram warm up: what does it mean?\n",
    "    \n",
    "hello  ⬅️ this is 1-gram\n",
    "\n",
    "hello 2024  ⬅️ this is 2-gram\n",
    "\n",
    "hello 2024!  ⬅️ 2-gram or 3-gram? it depends on how you split the text, but by default you split them by recognizing the whitespaces, i.e. 2-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab45da9-c5d9-4b89-aa9b-0563f293d989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "A Pattern Language is the second in a series of books which describe an entirely new attitude to arc\n"
     ]
    }
   ],
   "source": [
    "file = open(\"pattern_fix2.txt\", \"r\")  # open our txt file, read only (which means we can't use \"write()\" function later)\n",
    "file = file.read()\n",
    "\n",
    "print(type(file))  # our data comes in as string\n",
    "print(file[:100])  # print 0~100 elements of the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eab2b937-dc1e-4749-8a37-65f5f6c73c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'Pattern', 'Language', 'is', 'the', 'second', 'in', 'a', 'series', 'of', 'books', 'which', 'describe', 'an', 'entirely', 'new', 'attitude', 'to', 'architecture', 'and', 'planning.', 'The', 'books', 'are', 'intended', 'to', 'provide', 'a', 'complete', 'working', 'alternative', 'to', 'our', 'present', 'ideas', 'about', 'architecture,', 'building,', 'and', 'planning', '—', 'an', 'alternative', 'which', 'will,', 'we', 'hope,', 'gradually', 'replace', 'current']\n",
      "237949\n"
     ]
    }
   ],
   "source": [
    "sequence = file.split()  # \"The split() method splits a string into a list. You can specify the separator, default separator is any whitespace.\"\n",
    "\n",
    "print(sequence[:50])  # we can see 0~50 elements of the seq list\n",
    "print(len(sequence))  # this is the total length of the list or the number of elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3721155-1238-4f4c-9eaa-de2bc631ef76",
   "metadata": {},
   "source": [
    "<font color=\"#6A0DAD\"> How do we group these elements according to the \"n\" of \"n-gram\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3b0a115-f915-46c0-b5b8-69dedf9a7c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A', 'Pattern', 'Language', 'is', 'the'], ['Pattern', 'Language', 'is', 'the', 'second'], ['Language', 'is', 'the', 'second', 'in'], ['is', 'the', 'second', 'in', 'a'], ['the', 'second', 'in', 'a', 'series'], ['second', 'in', 'a', 'series', 'of'], ['in', 'a', 'series', 'of', 'books'], ['a', 'series', 'of', 'books', 'which'], ['series', 'of', 'books', 'which', 'describe'], ['of', 'books', 'which', 'describe', 'an']]\n"
     ]
    }
   ],
   "source": [
    "n_gram_number = 5  # you can change the number and run again\n",
    "n_gram_list = []\n",
    "\n",
    "for i in range(len(sequence)-n_gram_number+1):\n",
    "    n_gram_list.append(sequence[i:i+n_gram_number])\n",
    "\n",
    "print(n_gram_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712dbfe-312a-426d-893f-b224a285b14f",
   "metadata": {},
   "source": [
    "<font color=\"#6A0DAD\">\n",
    "How do we know the most common elements in the n_gram_list?\n",
    "\n",
    "Note that lists are mutable objects with no fixed hash value. Therefore, if we want to count the occurrences of elements with the same pattern, we have to tuple them first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e4bba2b-0e57-49ec-b691-cea90f5b5e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'Pattern', 'Language', 'is', 'the'), ('Pattern', 'Language', 'is', 'the', 'second'), ('Language', 'is', 'the', 'second', 'in'), ('is', 'the', 'second', 'in', 'a'), ('the', 'second', 'in', 'a', 'series'), ('second', 'in', 'a', 'series', 'of'), ('in', 'a', 'series', 'of', 'books'), ('a', 'series', 'of', 'books', 'which'), ('series', 'of', 'books', 'which', 'describe'), ('of', 'books', 'which', 'describe', 'an')]\n"
     ]
    }
   ],
   "source": [
    "n_gram_number = 5\n",
    "n_gram_list_tupled = []\n",
    "\n",
    "for i in range(len(sequence)-n_gram_number+1):\n",
    "    n_gram_list_tupled.append(tuple(sequence[i:i+n_gram_number]))\n",
    "\n",
    "print(n_gram_list_tupled[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a98534-a8f0-4f9c-bb4d-089d5aebdbb7",
   "metadata": {},
   "source": [
    "<font color=\"#6A0DAD\">\n",
    "Then we can count the occurrence times, and list the most frequent ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7805a4e4-5dac-4280-8fc6-298776e27b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('in', 'such', 'a', 'way', 'that'), 54),\n",
       " (('THE', 'SHAPE', 'OF', 'INDOOR', 'SPACE'), 31),\n",
       " (('COMMON', 'AREAS', 'AT', 'THE', 'HEART'), 28),\n",
       " (('PRIVATE', 'TERRACE', 'ON', 'THE', 'STREET'), 25),\n",
       " (('...', 'this', 'pattern', 'helps', 'to'), 22),\n",
       " (('LIGHT', 'ON', 'TWO', 'SIDES', 'OF'), 20)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(n_gram_list_tupled).most_common(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65c1499-8cb1-4be6-8cb5-871741423cae",
   "metadata": {},
   "source": [
    "<font color=\"#6A0DAD\">\n",
    "\"('in', 'such', 'a', 'way', 'that')\" appears 54 times. Is it a mantra?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61256eac-9c5c-4cc4-900b-8e606fd9d11b",
   "metadata": {},
   "source": [
    "<font color=\"#6A0DAD\">\n",
    "    \n",
    "### 1.2 n-gram advanced: how to generate the next word/element?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645c6f80-6aba-4849-acb1-def7dc0baaaf",
   "metadata": {},
   "source": [
    "<font color=\"#6A0DAD\">\n",
    "To find the next possible word/element, we create a dictionary with the tuple sequence as the key. For each key, the word/element immediately following the sequence will be appended as the value of the key.\n",
    "    \n",
    "But it is not saying 1 key has only 1 value. For example, \"('in', 'such', 'a', 'way', 'that'), 54)\", the sequence \"('in', 'such', 'a', 'way', 'that'), 54)\" occurs 54 times, and the word/element immediately following it may be different, so we need to create a list of all the possibilities for each key and then append all 54 possibilities to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88500d98-df55-4fbb-8d6b-2683e9de950b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "n_gram_number = 5\n",
    "n_gram_dictionary = {}\n",
    "\n",
    "for i in range(len(sequence)-n_gram_number):\n",
    "    # print(tuple(sequence[i:i+n_gram_number]))\n",
    "    gram = tuple(sequence[i:i+n_gram_number])\n",
    "    next = sequence[i+n_gram_number]\n",
    "    if gram not in n_gram_dictionary:\n",
    "        n_gram_dictionary[gram] = []\n",
    "    n_gram_dictionary[gram].append(next)\n",
    "\n",
    "# print(list(n_gram_dictionary.keys())[:10])\n",
    "\n",
    "n_gram_dictionary_length = {}\n",
    "\n",
    "for key in list(n_gram_dictionary.keys()):\n",
    "    n_gram_dictionary_length[key] = len(n_gram_dictionary[key])\n",
    "    \n",
    "print(n_gram_dictionary_length[('in', 'such', 'a', 'way', 'that')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4216198-2bf0-47d9-9587-e354f84b752e",
   "metadata": {},
   "source": [
    "<font color=\"#6A0DAD\">\n",
    "How to generate the next word/element? \n",
    "\n",
    "We can choose the next word/element randomly (or the one that appears most frequently)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aff863a-fc6f-414e-b89b-e56d7f07d711",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you',\n",
       " 'you',\n",
       " 'it',\n",
       " 'every',\n",
       " 'many',\n",
       " 'every',\n",
       " 'within',\n",
       " 'children',\n",
       " 'one',\n",
       " 'it',\n",
       " 'they',\n",
       " 'they',\n",
       " 'we',\n",
       " 'they',\n",
       " 'the',\n",
       " 'people',\n",
       " 'the',\n",
       " 'they',\n",
       " 'they',\n",
       " 'they',\n",
       " 'the',\n",
       " 'every',\n",
       " 'work',\n",
       " 'it',\n",
       " 'they',\n",
       " 'each',\n",
       " 'all',\n",
       " 'people',\n",
       " 'they',\n",
       " 'there',\n",
       " 'you',\n",
       " 'the',\n",
       " 'people',\n",
       " 'a',\n",
       " 'there',\n",
       " 'they',\n",
       " 'they',\n",
       " 'people',\n",
       " 'the',\n",
       " 'the',\n",
       " 'angles',\n",
       " 'their',\n",
       " 'such',\n",
       " 'each',\n",
       " 'every',\n",
       " 'it',\n",
       " 'some',\n",
       " 'he',\n",
       " 'they',\n",
       " 'they',\n",
       " 'the',\n",
       " 'the',\n",
       " 'they',\n",
       " 'there']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram_dictionary[('in', 'such', 'a', 'way', 'that')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b09ebed-346f-4fea-b806-f46ae97d67fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# choose the next word/element randomly\n",
    "random_element = random.choice(n_gram_dictionary[('in', 'such', 'a', 'way', 'that')])\n",
    "print(random_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a0f58d7-c8bd-4447-8cdc-b26c5ff0e2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people : 0.07407407407407407\n",
      "such : 0.018518518518518517\n",
      "many : 0.018518518518518517\n",
      "work : 0.018518518518518517\n",
      "the : 0.14814814814814814\n",
      "angles : 0.018518518518518517\n",
      "it : 0.07407407407407407\n",
      "there : 0.05555555555555555\n",
      "one : 0.018518518518518517\n",
      "within : 0.018518518518518517\n",
      "he : 0.018518518518518517\n",
      "you : 0.05555555555555555\n",
      "they : 0.24074074074074073\n",
      "their : 0.018518518518518517\n",
      "every : 0.07407407407407407\n",
      "all : 0.018518518518518517\n",
      "children : 0.018518518518518517\n",
      "some : 0.018518518518518517\n",
      "each : 0.037037037037037035\n",
      "a : 0.018518518518518517\n",
      "we : 0.018518518518518517\n",
      "['people', 'the', 'it', 'there', 'you', 'they', 'every']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'they'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or choose the next word/element based on a minimum frequency\n",
    "value_all =  n_gram_dictionary[('in', 'such', 'a', 'way', 'that')]\n",
    "value_unique = list(set(value_all))\n",
    "\n",
    "min_frequency = 0.05\n",
    "value_above_min_frequency = []\n",
    "\n",
    "for value in value_unique:\n",
    "    value_frequency = value_all.count(value)/len(value_all)\n",
    "    print(value, \":\", value_frequency)\n",
    "    if value_frequency >= min_frequency:\n",
    "        value_above_min_frequency.append(value)\n",
    "        \n",
    "print(value_above_min_frequency)\n",
    "random.choice(value_above_min_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e927c0-d3f2-4f15-ae32-3a30f7e9986c",
   "metadata": {},
   "source": [
    "<font color=\"#6A0DAD\">\n",
    "    \n",
    "## 2 combined: generate text with markov chain - random\n",
    "\n",
    "The output is generated randomly regardless the frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d48c2cd-7aa7-4021-b872-8b490d23dcab",
   "metadata": {},
   "source": [
    "<font color=\"#6A0DAD\">\n",
    "Now we are going to generate text! Here we use 1-gram ~ 3-gram since our dataset is small. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "703d5bcc-b15d-4540-bc8b-87b7fa5f6358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Pattern Language Which should be in modern apartment buildings have the house, nor pass through, and 15 households, according as well. And third, and away completely. Many of fence it rains, yet still leave their own entrances — at will. As the first case, and beams, and physically separate from one flight of these comers where people well. She finds himself half inch or dramatic forms the food and carts and re-create playgrounds does well together on the front of the most houselike of the center of life the curb and a bay windows, because it is missing in its transition with roughly square panels half by a single roof.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_dictionary(file, n_gram_number):\n",
    "    sequence = open(file, \"r\").read().split()\n",
    "    n_gram_dictionary = {}\n",
    "    for i in range(len(sequence)-n_gram_number):\n",
    "        gram = tuple(sequence[i:i+n_gram_number])\n",
    "        next = sequence[i+n_gram_number]\n",
    "        if gram not in n_gram_dictionary:\n",
    "            n_gram_dictionary[gram] = []\n",
    "        n_gram_dictionary[gram].append(next)\n",
    "\n",
    "    return n_gram_dictionary\n",
    "\n",
    "def generate_text(input, output_length, n_gram_number):\n",
    "    n_gram_dictionary = create_dictionary(file, n_gram_number)\n",
    "    input_list = input.split()\n",
    "    if len(input.split()) >= n_gram_number:\n",
    "        for i in range(output_length):\n",
    "            input_start = input_list[-n_gram_number:]  # we start from the last elements/words that can jointly be treated as a complete gram\n",
    "            next = random.choice(n_gram_dictionary[tuple(input_start)])\n",
    "            if next is not None:\n",
    "                input_list.append(next)\n",
    "        \n",
    "        # check punctuation, if not ends with \".\" or \"?\" or \"!\" or \")\", we let it continue generating until there is a proper punctuation\n",
    "        while not list(input_list[-1])[-1].endswith(\".\" or \"?\" or \"!\" or \")\"):\n",
    "            input_start = input_list[-n_gram_number:]\n",
    "            next = random.choice(n_gram_dictionary[tuple(input_start)])\n",
    "            if next is not None:\n",
    "                input_list.append(next)\n",
    "    else:\n",
    "        print(\"the input length is shorter than the n\")\n",
    "\n",
    "    # join the list\n",
    "    output = \" \".join(input_list)\n",
    "    return output\n",
    "            \n",
    "\n",
    "file = \"pattern_fix2.txt\"\n",
    "n_gram_number = 1\n",
    "input = 'A Pattern Language'\n",
    "output_length = 100\n",
    "\n",
    "generate_text(input, output_length, n_gram_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f746936-0a43-48ea-bc8a-cf3a69c9be4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Pattern Language Which Generates Multi-Service Centers, pp. 29–103. A good kitchen with our house. This pattern helps to produce complex system, we recommend a cloth and it establishes 20 minute expressions on horseback, and make it has no wall and Interpersonal Competence, Chicago, Illinois, 1967, pp. 80–87). There is a Psychiatrically Diagnosed Group of the alcove with ROOT FOUNDATIONS (214), the only part of walls — COMMUNITY OF LIGHT** ... inside the house, another matter. Gray gravel path, themselves swamped by filling it will not normal. In small factory for reading. We know, it is, not degrade it. Therefore: Wherever possible, they draw a multitude of plants placed correctly.\n",
      "A Pattern Language This pattern would be woken by the political struggles. In existing grid can gradually weaving a threshold where this neighborhood, animals into which is the terror of the south for sitting height of light, or industrial park to help to the pegs. Therefore; At first by some other simple mechanism may not require trim to make sure people stuff of chickenwire, paper, scraps of Greece. It is a few small courtyard. And think about half-open walls can stay alive. We still a review of buildings: the chairs are not being away from a special paths are covered seats, invites you are woven into the regions which you WINGS OF LEARNING* ...\n",
      "A Pattern Language We believe that even when people working, bathing, sleeping, dressing areas and talking. And in vast range of STRUCTURE (206), the corners, and therefore specify that the problem will therefore makes sure that the goals should say categorically that there is more than two miles across, to have almost automatically as possible to know from place in the site, with a roof only an attic rooms; the site a part of connection : Children Living Structure and CEILING LAYOUT 211. THICKENING THE FAMILY 76. HOUSE FOR A Pattern Language” with the work in; locate the building. We get hold out can help to homes and those rooms with its power and large enough only suitable for landmarks, thinking about the teenage suicide, drug addiction, and the principle and sides) with the city; his house well-defined individual territories according to reduce the important parts of the mean that the few relatives and curtains — MOSAIC OF SUBCULTURES (8) and whole.\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(input, output_length, n_gram_number))\n",
    "print(generate_text(input, output_length, n_gram_number))\n",
    "print(generate_text(input, output_length, n_gram_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc385394-5a16-4b2f-a65d-765584061382",
   "metadata": {},
   "source": [
    "<font color=\"#6A0DAD\">\n",
    "\n",
    "## 3 combined: generate text with markov chain - minimum frequency\n",
    "\n",
    "We set a minimum frequency to limit the randomness to some extend. You can observe the outputs and find how similar they are. When you see the following prompt, it means you need to change the value of the minimum frequency.\n",
    ">......break because no value is more frequent than this min_frequency......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13d01e99-f9b2-4c80-8625-aaa7cec48a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Pattern Language is the case of people are free standing as they come into contact with people, an evil lack of compassion and a field of knowledge, or a window on the fact that, for a raised Walk? Our experiments on this side there is always like that, it is the case where there were doctors’ offices, and it creates in tolerable rifts in people’s homes — HOME WORKSHOP (157). The size of rooms? In some fashion, low ceilings — THICK WALLS (197).... 199 SUNNY COUNTER* ... FARMHOUSE KITCHEN 140. PRIVATE TERRACE ON THE STREET** ... the land, they can even be possible if each house cluster can create an institutional atmosphere, quite at odds with social and political and economic reasons, without regard for tew and climate, they will approach the site. \n",
      "\n",
      "A Pattern Language is the most dramatic empirical evidence that one subculture is being inhibited by pressure dipping in pentachlorophenol. We also know, from the building to be on view, and watch TV alone, the way into the house allows you, in your mind. Therefore: Lay out abundant footpaths and bike paths and also having a night on the north strikes the ground immediately beside the entrance, too, comes into view; and the private worlds as entirely individual and family are able to see if the space never becomes lively. In more detail: people gravitate naturally toward the view from the common area a part in this language here? The fact is, that current development hardly ever close to the people in Grand Central are strangers, and to form ACTIVITY NODES 31. \n",
      "\n",
      "A Pattern Language is the best places. Buildings must always get a full connection, like an erector set, but that instead, they can get. Children play in the building fronts into the land ... Within the gap in sevices. Two colleagues of ours have tested the efficiency and potential stability of the people he most wants to learn to use them. But the sheer size of groups that have to meet, at least 12 inches, 9 inches, 6 inches, and 3 blocks, where people’s behavior in outdoor spaces (shown as A, B, and C), and hip the roofs of a large rambling house or office — SELF GOVERNING WORKSHOPS AND OFFICES** ... \n",
      "\n",
      "A Pattern Language is the one where it meets the public thoroughfare is indoors, make it abundantly clear that we make the concept of childbirth as a room analyzed in detail under SMALL PUBLIC SQUARE (61). Third, the fact is that most contact with rural life. In fact these networks now exist, but they also want it to create FILTERED LIGHT (238) to prevent cracks which run all water drains into the building edge is alive. It is this evidence which suggests that people in good condition indefinitely. 235 SOFT INSIDE WALLS 236. WINDOWS WHICH OPKN WIDE (236). Give the local schools, so children can safely wander on their proper character, by building low walls and walls, can simply be devoured. \n",
      "\n",
      "A Pattern Language is the case where there were three columns standing, supporting the roof some extra kind of natural resin in a room, although rooms are not met and problems are critical. The bays of the building to keep healing and improving the social arguments. Columns made of wooden planks and boards and interior skin plywood or gyp board. In either case, use the pattern. Let us consider drinking more in contact with true rural land to be in always seem to contradict them. The continuity of a house is essentially triangular. To keep main roads for long overnight stays. 5. Payment might be frightened or confused could find their way of looking after tiny children playing at the end are “smaller.” Almost all of these are two unusually comfortable situations. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_dictionary(file, n_gram_number):\n",
    "    sequence = open(file, \"r\").read().split()\n",
    "    n_gram_dictionary = {}\n",
    "    for i in range(len(sequence)-n_gram_number):\n",
    "        gram = tuple(sequence[i:i+n_gram_number])\n",
    "        next = sequence[i+n_gram_number]\n",
    "        if gram not in n_gram_dictionary:\n",
    "            n_gram_dictionary[gram] = []\n",
    "        n_gram_dictionary[gram].append(next)\n",
    "\n",
    "    return n_gram_dictionary\n",
    "\n",
    "def generate_text(input, output_length, n_gram_number, min_frequency):\n",
    "    n_gram_dictionary = create_dictionary(file, n_gram_number)\n",
    "    input_list = input.split()\n",
    "    if len(input.split()) >= n_gram_number:\n",
    "        for i in range(output_length):\n",
    "            input_start = input_list[-n_gram_number:]  # we start from the last elements/words that can jointly be treated as a complete gram\n",
    "\n",
    "            next_value_all =  n_gram_dictionary[tuple(input_start)]\n",
    "            next_value_unique = list(set(next_value_all))\n",
    "            value_above_min_frequency = []\n",
    "\n",
    "            for value in next_value_unique:\n",
    "                value_frequency = next_value_all.count(value)/len(next_value_all)\n",
    "                if value_frequency >= min_frequency:\n",
    "                    value_above_min_frequency.append(value) \n",
    "            if value_above_min_frequency:\n",
    "                next = random.choice(value_above_min_frequency)\n",
    "                if next is not None:\n",
    "                    input_list.append(next)\n",
    "\n",
    "            else: \n",
    "                input_list.append('......break because no value is above this min_frequency......')\n",
    "                break\n",
    "\n",
    "        \n",
    "        # check punctuation, if not ends with \".\" or \"?\" or \"!\" or \")\", we let it continue generating until there is a proper punctuation\n",
    "        while not list(input_list[-1])[-1].endswith(\".\" or \"?\" or \"!\" or \")\"):\n",
    "            input_start = input_list[-n_gram_number:] \n",
    "\n",
    "            next_value_all =  n_gram_dictionary[tuple(input_start)]\n",
    "            next_value_unique = list(set(next_value_all))\n",
    "            value_above_min_frequency = []\n",
    "\n",
    "            for value in next_value_unique:\n",
    "                value_frequency = next_value_all.count(value)/len(next_value_all)\n",
    "                if value_frequency >= min_frequency:\n",
    "                    value_above_min_frequency.append(value) \n",
    "            if value_above_min_frequency:\n",
    "                next = random.choice(value_above_min_frequency)\n",
    "                if next is not None:\n",
    "                    input_list.append(next)\n",
    "\n",
    "            else: \n",
    "                input_list.append('......break because no value is more frequent than this min_frequency......')\n",
    "                break\n",
    "                \n",
    "    else:\n",
    "        print(\"the input length is shorter than the n\")\n",
    "\n",
    "    # join the list\n",
    "    output = \" \".join(input_list)\n",
    "    return output\n",
    "            \n",
    "\n",
    "file = \"pattern_fix2.txt\"\n",
    "n_gram_number = 2\n",
    "input = 'A Pattern Language'\n",
    "output_length = 100\n",
    "min_frequency = 0.01\n",
    "\n",
    "print(generate_text(input, output_length, n_gram_number, min_frequency),\"\\n\")\n",
    "print(generate_text(input, output_length, n_gram_number, min_frequency),\"\\n\")\n",
    "print(generate_text(input, output_length, n_gram_number, min_frequency),\"\\n\")\n",
    "print(generate_text(input, output_length, n_gram_number, min_frequency),\"\\n\")\n",
    "print(generate_text(input, output_length, n_gram_number, min_frequency),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d57cc4a-5c3c-4feb-a41b-5bb8aac5a521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396224f3-e2fb-475e-a5cb-0f045e398dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
