{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39954f36-cd83-4915-a6c2-992918112c8f",
   "metadata": {},
   "source": [
    "<font color=\"#6A0DAD\">\n",
    "\n",
    "## 1 generate from a pretrained model\n",
    "\n",
    "Since we have already exported our models, we can load them directly now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2daf900-1a04-49d7-94b8-51154af1c5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-27 02:43:39.513507: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-27 02:43:39.513555: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-27 02:43:39.514594: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-27 02:43:39.521949: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3720a72c-0654-4488-934c-7ce04c4a0066",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pretrained_generator = tf.saved_model.load('./generator_vocab10000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a85e2d-757b-4aaa-b739-bd5ec684b155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_generation(sentence, generated_text):\n",
    "    print(f'{\"Input:\":15s}: {sentence}')\n",
    "    print(f'{\"Generation\":15s}: {generated_text}')\n",
    "\n",
    "def print_sentence(generated_text):\n",
    "    text = \"\"\n",
    "    for word in generated_text.numpy()[0]:\n",
    "        text += word.decode() + \" \"\n",
    "    print(f'{\"Text\":15s}: {text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b510a22-cf7e-4688-a3c4-0e9b7f6c0a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1703645047.650659  207098 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA A100 80GB PCIe\" frequency: 1410 num_cores: 108 environment { key: \"architecture\" value: \"8.0\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 41943040 shared_memory_size_per_multiprocessor: 167936 memory_size: 932839424 bandwidth: 1935360000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "W0000 00:00:1703645047.651951  207098 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA A100 80GB PCIe\" frequency: 1410 num_cores: 108 environment { key: \"architecture\" value: \"8.0\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 41943040 shared_memory_size_per_multiprocessor: 167936 memory_size: 932839424 bandwidth: 1935360000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "W0000 00:00:1703645047.653251  207098 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA A100 80GB PCIe\" frequency: 1410 num_cores: 108 environment { key: \"architecture\" value: \"8.0\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 41943040 shared_memory_size_per_multiprocessor: 167936 memory_size: 932839424 bandwidth: 1935360000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "W0000 00:00:1703645047.654397  207098 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA A100 80GB PCIe\" frequency: 1410 num_cores: 108 environment { key: \"architecture\" value: \"8.0\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 41943040 shared_memory_size_per_multiprocessor: 167936 memory_size: 932839424 bandwidth: 1935360000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-12-27 02:44:09.213697: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:         : A Pattern Language is\n",
      "Generation     : [[b'' b'used' b'in' b'control' b'of' b'[UNK]' b'systems.' b'a' b'pattern'\n",
      "  b'makes' b'an' b'outcome' b'not' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      "  b'when' b'an' b'action' b'will' b'scripts' b'how' b'it' b'[UNK]' b'and'\n",
      "  b'[UNK]' b'with' b'remote' b'work' b'[UNK]' b'while' b'[UNK]' b'there'\n",
      "  b'are' b'different' b'types' b'of' b'exception' b'tests' b'that' b'can'\n",
      "  b'be' b'achieved' b'automatically' b'by' b'a' b'defined' b'location.'\n",
      "  b'the' b'pattern' b'of' b'[UNK]' b'can' b'be' b'used' b'to' b'write'\n",
      "  b'code' b'in' b'a' b'[UNK]' b'section' b'of' b'an' b'outcome' b'while'\n",
      "  b'otherwise.' b'(see' b'[UNK]' b'how' b'to' b'write' b'a' b'script'\n",
      "  b'[UNK]' b'\\xe2\\x80\\x94' b'[UNK]' b'\\xe2\\x80\\x94' b'[UNK]' b'[UNK]'\n",
      "  b'[UNK]' b'[UNK]' b'\\xe2\\x80\\x94' b'[UNK]' b'paul' b'[UNK]' b'[UNK]'\n",
      "  b'[UNK]' b'\\xe2\\x80\\x94' b'[UNK]' b'[UNK]' b'[UNK]' b'code' b'held'\n",
      "  b'by' b'[UNK]' b'kind,' b'[UNK]' b'coffee' b'above' b'all,' b'the'\n",
      "  b'scenario' b'that' b'works' b'is' b'very' b'like' b'this:' b'[UNK]'\n",
      "  b'automated' b'[UNK]' b'[UNK]' b'.' b'the' b'way' b'it' b'works' b'is'\n",
      "  b'a' b'way' b'to' b'write' b'code.' b'after' b'[UNK]' b'with' b'[UNK]'\n",
      "  b'this' b'is' b'implemented' b'in' b'the' b'original' b'java' b'[UNK]'\n",
      "  b'i' b'am' b'the' b'first' b'[UNK]' b'runtime' b'ourselves.' b'an'\n",
      "  b'[UNK]' b'[UNK]' b'helps' b'[UNK]' b'[UNK]' b'*' b'*' b'[UNK]'\n",
      "  b'[UNK]' b'is' b'such' b'a' b'special' b'took' b'the' b'method' b'in'\n",
      "  b'the' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'function' b'that' b'[UNK]'\n",
      "  b'[UNK]' b'[UNK]' b'to' b'facilitate' b'similar' b'to' b'one' b'of'\n",
      "  b'the' b'previous' b'was' b'able' b'to' b'process' b'a' b'commonly'\n",
      "  b'called' b'[UNK]' b'for' b'a' b'[UNK]' b'code' b'[UNK]' b'the' b'code'\n",
      "  b'is' b'used' b'for' b'[UNK]' b'[UNK]' b'tasks.' b'the' b'core'\n",
      "  b'functionality.' b'then' b'now,' b'so' b'we' b'have' b'achieved' b'by'\n",
      "  b'the' b'software' b'using' b'[UNK]' b'validation' b'.' b'[UNK]' b'and'\n",
      "  b'[UNK]' b'function' b'and' b'the' b'python' b'/' b'[UNK]' b'in'\n",
      "  b'[UNK]' b'it' b'was' b'used' b'by' b'[UNK]' b'tools.' b'see' b'the'\n",
      "  b'initial' b'validation' b'to' b'the' b'[UNK]']]\n",
      "Text           :  used in control of [UNK] systems. a pattern makes an outcome not [UNK] [UNK] [UNK] [UNK] when an action will scripts how it [UNK] and [UNK] with remote work [UNK] while [UNK] there are different types of exception tests that can be achieved automatically by a defined location. the pattern of [UNK] can be used to write code in a [UNK] section of an outcome while otherwise. (see [UNK] how to write a script [UNK] — [UNK] — [UNK] [UNK] [UNK] [UNK] — [UNK] paul [UNK] [UNK] [UNK] — [UNK] [UNK] [UNK] code held by [UNK] kind, [UNK] coffee above all, the scenario that works is very like this: [UNK] automated [UNK] [UNK] . the way it works is a way to write code. after [UNK] with [UNK] this is implemented in the original java [UNK] i am the first [UNK] runtime ourselves. an [UNK] [UNK] helps [UNK] [UNK] * * [UNK] [UNK] is such a special took the method in the [UNK] [UNK] [UNK] [UNK] function that [UNK] [UNK] [UNK] to facilitate similar to one of the previous was able to process a commonly called [UNK] for a [UNK] code [UNK] the code is used for [UNK] [UNK] tasks. the core functionality. then now, so we have achieved by the software using [UNK] validation . [UNK] and [UNK] function and the python / [UNK] in [UNK] it was used by [UNK] tools. see the initial validation to the [UNK] \n"
     ]
    }
   ],
   "source": [
    "sentence = \"A Pattern Language is\"\n",
    "generated_text = pretrained_generator(sentence)\n",
    "print_generation(sentence, generated_text)\n",
    "print_sentence(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899c13b3-bda0-4755-8c13-21f73b50e67e",
   "metadata": {},
   "source": [
    "<font color=\"#6A0DAD\">\n",
    "\n",
    "## 2 compare pretrained models with different vocab size\n",
    "\n",
    "As you see, there are lots of `[UNK]` in the generated text, that's because the 5000 vocab size is too small. So we are going to try 10000 vocab and maybe 15000. Also we may have to calculate the dataset's vocab size to set a proper number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05970e11-fda1-43a0-a789-149cce720a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def combined_content(generated_text):\n",
    "    text = \"\"\n",
    "    for word in generated_text.numpy()[0]:\n",
    "        text += word.decode() + \" \"\n",
    "    combined_content = sentence + text\n",
    "    print(combined_content)\n",
    "    combined_content_list = combined_content.split()\n",
    "    print(Counter(combined_content_list)['[UNK]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70db1e1a-bc02-41c8-94e4-b5b052933d62",
   "metadata": {},
   "source": [
    "<font color=\"#6A0DAD\">\n",
    "\n",
    "### 2.1 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4947139-70ee-46a2-bbac-ccaac0feaef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1703645731.660371  207098 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA A100 80GB PCIe\" frequency: 1410 num_cores: 108 environment { key: \"architecture\" value: \"8.0\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 41943040 shared_memory_size_per_multiprocessor: 167936 memory_size: 932839424 bandwidth: 1935360000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "W0000 00:00:1703645731.661558  207098 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA A100 80GB PCIe\" frequency: 1410 num_cores: 108 environment { key: \"architecture\" value: \"8.0\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 41943040 shared_memory_size_per_multiprocessor: 167936 memory_size: 932839424 bandwidth: 1935360000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "W0000 00:00:1703645731.662620  207098 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA A100 80GB PCIe\" frequency: 1410 num_cores: 108 environment { key: \"architecture\" value: \"8.0\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 41943040 shared_memory_size_per_multiprocessor: 167936 memory_size: 932839424 bandwidth: 1935360000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "W0000 00:00:1703645731.663754  207098 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA A100 80GB PCIe\" frequency: 1410 num_cores: 108 environment { key: \"architecture\" value: \"8.0\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 41943040 shared_memory_size_per_multiprocessor: 167936 memory_size: 932839424 bandwidth: 1935360000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Pattern Language is a [UNK] experiment and a tough task. why it is so [UNK] it takes some of the previous [UNK] [UNK] we will not change their [UNK] problems, but it’ll have become [UNK] with the intent of being the only part of a [UNK] is [UNK] as part of a [UNK] the effect of the order in [UNK] we will try to remove all those [UNK] and work so hard to catch up with [UNK] [UNK] when we’re not an [UNK] [UNK] we think for a [UNK] solution. how often do we become a [UNK] [UNK] technology can’t change the way we [UNK] changing our sites by [UNK] and other aspects of our time. the kind of [UNK] we humans have always been in [UNK] and processing [UNK] and we [UNK] challenges are so [UNK] the [UNK] to create [UNK] we do not only to get to [UNK] a complex solutions they all know we know how to [UNK] for it, something with [UNK] but it just because of the ideas that might not [UNK] in [UNK] all [UNK] due to all these technologies can [UNK] in their [UNK] it’s [UNK] over the amount of [UNK] right, but the [UNK] [UNK] strength and [UNK] everything we are [UNK] to [UNK] so hard to make it is much of [UNK] [UNK] but we replace the same [UNK] resources. [UNK] [UNK] with all in every one of all the [UNK] are convenient [UNK] \n",
      "49\n"
     ]
    }
   ],
   "source": [
    "pretrained_generator = tf.saved_model.load('./generator_vocab5000')\n",
    "\n",
    "sentence = \"A Pattern Language is\"\n",
    "generated_text = pretrained_generator(sentence)\n",
    "combined_content(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5323753-e782-43de-9a9f-9659a5216370",
   "metadata": {},
   "source": [
    "<font color=\"#6A0DAD\">\n",
    "\n",
    "### 2.2 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "401d3963-4405-4c8e-b154-e98f13398dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1703645747.331220  207098 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA A100 80GB PCIe\" frequency: 1410 num_cores: 108 environment { key: \"architecture\" value: \"8.0\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 41943040 shared_memory_size_per_multiprocessor: 167936 memory_size: 932839424 bandwidth: 1935360000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "W0000 00:00:1703645747.332571  207098 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA A100 80GB PCIe\" frequency: 1410 num_cores: 108 environment { key: \"architecture\" value: \"8.0\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 41943040 shared_memory_size_per_multiprocessor: 167936 memory_size: 932839424 bandwidth: 1935360000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "W0000 00:00:1703645747.333642  207098 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA A100 80GB PCIe\" frequency: 1410 num_cores: 108 environment { key: \"architecture\" value: \"8.0\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 41943040 shared_memory_size_per_multiprocessor: 167936 memory_size: 932839424 bandwidth: 1935360000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "W0000 00:00:1703645747.334861  207098 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA A100 80GB PCIe\" frequency: 1410 num_cores: 108 environment { key: \"architecture\" value: \"8.0\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 41943040 shared_memory_size_per_multiprocessor: 167936 memory_size: 932839424 bandwidth: 1935360000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Pattern Language is widely used in analysis. all applications are designed and in a way that a long time to view your time is an issue, and to the extent that systems are quite [UNK] to be built without any technological in. by doing that, they are [UNK] in product [UNK] the experience of manually education, and those in need of commercial behavior for [UNK] at any time, there is no need of quality [UNK] they are used in corporate and business area. not surprisingly, it is understandable that when folks don’t understand too much. yet, alongside electronic devices on a constant basis for those like [UNK] to, you always need to consider how to turn a [UNK] into the audience amongst the next. additionally, there are always instances where to look of people to face vendors cited and [UNK] in the traditional [UNK] in the same cultures across the digital [UNK] and on individual platforms — the [UNK] each other people for those marketplaces into categories of their [UNK] by both those of tech markets that one the world [UNK] [UNK] you for [UNK] [UNK] are being documented on the [UNK] [UNK] properties. but once in figuring out and most of the online countries may have very electronic could not only [UNK] [UNK] this will enjoy those in [UNK] in turn, may not millions of [UNK] in other [UNK] approaches that [UNK] compromise james [UNK] for many, these disruptive tech that many \n",
      "25\n"
     ]
    }
   ],
   "source": [
    "pretrained_generator = tf.saved_model.load('./generator_vocab10000')\n",
    "\n",
    "sentence = \"A Pattern Language is\"\n",
    "generated_text = pretrained_generator(sentence)\n",
    "combined_content(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e0e82c-29c9-433a-99c1-4b023fc63fe9",
   "metadata": {},
   "source": [
    "<font color=\"#6A0DAD\">\n",
    "\n",
    "### 2.x compare `[UNK]` quantity\n",
    "\n",
    "I've test 6 times and this is the record:\n",
    "- 5000 vs 10000\n",
    "    - 44:26 = 1.69\n",
    "    - 72:54 = 1.33\n",
    "    - 58:18 = 3.22\n",
    "    - 33:149 = 0.22\n",
    "    - 53:48 = 1.10\n",
    "    - 46:30 = 1.53\n",
    " \n",
    "It seems setting a higher vocab size works, but we can have more tests."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
